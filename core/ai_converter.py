# core/ai_converter.py
"""
AI è½¬æ¢æ¨¡å— (Step 03)

åŠŸèƒ½ï¼š
- æ¥æ”¶æ¸…æ´—åçš„ WAV æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ *_clean.wavï¼‰
- æ ¹æ®é…ç½®/ç¯å¢ƒå†³å®šä½¿ç”¨ Basic Pitch æ¨¡å‹è¿˜æ˜¯ Stub (æ¡©) æ¨¡å¼
- è¾“å‡º MIDI æ–‡ä»¶ (.mid)ï¼Œé»˜è®¤æ”¾åœ¨ settings.output_dir ä¸­

æ ¸å¿ƒå¯¹å¤–å‡½æ•°ï¼š
    audio_to_midi(audio_path, output_dir=None) -> Path

æ¨¡å¼è§„åˆ™ï¼ˆå…¼å®¹å¢å¼ºï¼‰ï¼š
- è‹¥ç¯å¢ƒå˜é‡ H2S_AI_MODE=stub|real|autoï¼Œåˆ™ä¼˜å…ˆæŒ‰å®ƒæ‰§è¡Œ
- å¦åˆ™æŒ‰ settings.use_stub_converterï¼š
    - True  -> stub
    - False -> autoï¼ˆä¼˜å…ˆ realï¼Œå¤±è´¥è‡ªåŠ¨å›é€€ stubï¼Œä¿è¯ demo æ›´ç¨³ï¼‰
"""
from __future__ import annotations

import inspect
import logging
import os
from pathlib import Path
from typing import Optional, Union, Literal

from core.config import get_settings

logger = logging.getLogger(__name__)

AIMode = Literal["auto", "real", "stub"]


def _resolve_ai_mode() -> AIMode:
    """
    Determine AI mode with highest priority:
    1) env var H2S_AI_MODE in {auto, real, stub}
    2) settings.use_stub_converter -> stub else auto
    """
    v = (os.getenv("H2S_AI_MODE") or "").strip().lower()
    if v in ("auto", "real", "stub"):
        return v  # type: ignore[return-value]

    settings = get_settings()
    return "stub" if getattr(settings, "use_stub_converter", False) else "auto"


def audio_to_midi(
    audio_path: Union[str, Path],
    output_dir: Optional[Union[str, Path]] = None,
) -> Path:
    """
    æ ¸å¿ƒè½¬æ¢å‡½æ•°ã€‚
    è¾“å…¥ï¼šWAV æ–‡ä»¶è·¯å¾„ï¼ˆå»ºè®®ä¼  *_clean.wavï¼‰
    è¾“å‡ºï¼šMIDI æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ outputs/<base_name>.midï¼‰

    å…¼å®¹è¡Œä¸ºï¼š
    - ä»ç„¶ä½¿ç”¨ base_name = stem.replace('_clean','') ç”Ÿæˆç›®æ ‡ <base_name>.mid
    - ä»ç„¶æ”¯æŒ settings.use_stub_converter
    - å¢å¼ºï¼šé»˜è®¤ autoï¼ˆä¼˜å…ˆ realï¼Œå¤±è´¥å›é€€ stubï¼‰
    """
    settings = get_settings()
    in_path = Path(audio_path)

    if not in_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {in_path}")

    out_dir = Path(output_dir) if output_dir else Path(settings.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    base_name = in_path.stem.replace("_clean", "")
    target_midi_path = out_dir / f"{base_name}.mid"

    mode = _resolve_ai_mode()
    logger.info("ğŸ¹ [AI Converter] å‡†å¤‡è½¬æ¢: %s (mode=%s)", in_path.name, mode)

    if mode == "stub":
        logger.warning("âš ï¸ ä½¿ç”¨ Stub æ¨¡å¼ (ç”Ÿæˆä¼ªé€  MIDI)ï¼Œä¸ä¼šè¿›è¡ŒçœŸå® AI æ¨ç†ã€‚")
        _create_dummy_midi(target_midi_path)
        logger.info("âœ… [Stub] MIDI ç”Ÿæˆå®Œæ¯•: %s", target_midi_path.name)
        return target_midi_path

    # real / auto: try basic_pitch
    try:
        midi_path = _audio_to_midi_basic_pitch(in_path, target_midi_path, out_dir)
        logger.info("âœ… [AI Converter] è½¬æ¢æˆåŠŸ: %s", midi_path.name)
        return midi_path
    except Exception as e:
        if mode == "real":
            raise
        logger.warning("âš ï¸ Real æ¨ç†å¤±è´¥ï¼Œè‡ªåŠ¨å›é€€ Stub: %s", e)
        _create_dummy_midi(target_midi_path)
        logger.info("âœ… [Stub Fallback] MIDI ç”Ÿæˆå®Œæ¯•: %s", target_midi_path.name)
        return target_midi_path


def _create_dummy_midi(path: Path) -> None:
    """
    ç”Ÿæˆä¸€ä¸ªæœ€å°åˆæ³•çš„ MIDI æ–‡ä»¶ï¼ˆçŸ­ç¶éŸ³ï¼šC-E-G-Cï¼‰ï¼Œç”¨äºæµ‹è¯•æµç¨‹ã€‚
    ç›´æ¥å†™å…¥äºŒè¿›åˆ¶æ•°æ®ï¼Œé¿å…ä¾èµ– mido ç­‰ç¬¬ä¸‰æ–¹åº“ã€‚
    """
    path.parent.mkdir(parents=True, exist_ok=True)

    def vlq(n: int) -> bytes:
        if n == 0:
            return b"\x00"
        out = bytearray()
        while n > 0:
            out.append(n & 0x7F)
            n >>= 7
        out.reverse()
        for i in range(len(out) - 1):
            out[i] |= 0x80
        return bytes(out)

    header = (
        b"MThd"
        + (6).to_bytes(4, "big")
        + (0).to_bytes(2, "big")
        + (1).to_bytes(2, "big")
        + (480).to_bytes(2, "big")
    )

    events = bytearray()
    events += vlq(0) + bytes([0xC0, 0x00])  # program change: piano

    notes = [60, 64, 67, 72]  # C4 E4 G4 C5
    velocity = 80
    dur = 480  # ticks

    for n in notes:
        events += vlq(0) + bytes([0x90, n, velocity])
        events += vlq(dur) + bytes([0x80, n, 0x00])

    events += vlq(0) + b"\xFF\x2F\x00"  # end of track

    track = b"MTrk" + len(events).to_bytes(4, "big") + bytes(events)

    with open(path, "wb") as f:
        f.write(header + track)


def _audio_to_midi_basic_pitch(
    in_path: Path,
    target_midi_path: Path,
    out_dir: Path,
) -> Path:
    """
    ä½¿ç”¨ Basic Pitch æ¨¡å‹å°†éŸ³é¢‘è½¬æ¢ä¸º MIDIã€‚

    å…³é”®ç‚¹ï¼š
    - ä½ å½“å‰å®‰è£…çš„ basic_pitch çš„ predict_and_save() éœ€è¦æ˜¾å¼ä¼ ï¼š
      save_midi / sonify_midi / save_model_outputs / save_notes / model_or_model_path
    - è¿™é‡Œé€šè¿‡ inspect.signature åšâ€œæŒ‰ç­¾åè¿‡æ»¤å‚æ•°â€ï¼Œé¿å…ç‰ˆæœ¬å·®å¼‚å¯¼è‡´å´©ã€‚
    - è¾“å‡ºæ–‡ä»¶åå¯èƒ½æ˜¯ï¼š
        <stem>.mid
        <stem>_basic_pitch.mid
      æœ€ç»ˆç»Ÿä¸€é‡å‘½åä¸º target_midi_pathï¼ˆå»æ‰ _clean çš„ <base_name>.midï¼‰
    """
    settings = get_settings()

    logger.info("ğŸ§  åŠ è½½ Basic Pitch æ¨ç†å™¨... (å¯èƒ½ä¼šè¾ƒæ…¢)")
    try:
        from basic_pitch.inference import predict_and_save  # type: ignore
        from basic_pitch import ICASSP_2022_MODEL_PATH  # type: ignore
    except Exception as e:
        raise RuntimeError(f"basic_pitch å¯¼å…¥å¤±è´¥ï¼š{e}")

    sig = inspect.signature(predict_and_save)
    params = sig.parameters

    onset = getattr(settings, "onset_threshold", None)
    frame = getattr(settings, "frame_threshold", None)

    # å€™é€‰å‚æ•°ï¼ˆä¼šæŒ‰ç­¾åè¿‡æ»¤ï¼Œåªä¼  predict_and_save çœŸæ­£æ”¯æŒçš„ï¼‰
    candidates = {
        # å¸¸è§ä¸»å‚æ•°
        "audio_path_list": [str(in_path)],
        "output_directory": str(out_dir),

        # ä½ å½“å‰ç‰ˆæœ¬é‡Œæ˜¯å¿…å¡«
        "save_midi": True,
        "sonify_midi": False,
        "save_model_outputs": False,
        "save_notes": False,
        "model_or_model_path": ICASSP_2022_MODEL_PATH,

        # å¯é€‰é˜ˆå€¼/æ—¶é•¿ï¼ˆæœ‰å°±ä¼ ï¼‰
        "onset_threshold": onset,
        "frame_threshold": frame,
        "minimum_note_length": 50.0,  # msï¼ˆæœ‰çš„ç‰ˆæœ¬ä¼šæ˜¯é»˜è®¤ 127.7ï¼‰
    }

    call_kwargs = {}
    for k, v in candidates.items():
        if v is None:
            continue
        if k in params:
            call_kwargs[k] = v

    # å…œåº•ï¼šå¦‚æœä½ çš„ç‰ˆæœ¬ä¸æ˜¯ audio_path_listï¼Œè€Œæ˜¯åˆ«çš„å‘½åï¼ˆæå°‘è§ï¼‰
    if "audio_path_list" not in call_kwargs:
        for alt in ("audio_paths", "audio_path", "audio_files"):
            if alt in params:
                call_kwargs[alt] = [str(in_path)]
                break

    # æœ€ä½å¿…å¡«æ£€æŸ¥ï¼šå¦‚æœç­¾åé‡Œè¿™äº›å‚æ•°æ²¡æœ‰é»˜è®¤å€¼ä½†æˆ‘ä»¬æ²¡æä¾›ï¼Œå°±ç›´æ¥æŠ¥æ¸…æ™°é”™è¯¯
    missing_required = []
    for name, p in params.items():
        if p.default is inspect._empty and p.kind in (p.POSITIONAL_OR_KEYWORD, p.KEYWORD_ONLY):
            if name not in call_kwargs:
                missing_required.append(name)
    if missing_required:
        raise TypeError(f"predict_and_save ç¼ºå°‘å¿…å¡«å‚æ•°ï¼š{missing_required}ï¼›å½“å‰å·²å‡†å¤‡å‚æ•°ï¼š{sorted(call_kwargs.keys())}")

    logger.info("ğŸ”¥ å¼€å§‹ AI æ¨ç† (å¯èƒ½éœ€è¦å‡ ç§’)...")
    predict_and_save(**call_kwargs)

    stem = in_path.stem
    base_name = stem.replace("_clean", "")

    candidates_out = [
        out_dir / f"{stem}.mid",
        out_dir / f"{stem}_basic_pitch.mid",
        out_dir / f"{base_name}.mid",
        out_dir / f"{base_name}_basic_pitch.mid",
    ]

    generated = next((p for p in candidates_out if p.exists()), None)

    if generated is None:
        mids = sorted(out_dir.glob("*.mid"), key=lambda p: p.stat().st_mtime, reverse=True)
        generated = mids[0] if mids else None

    if generated is None or not generated.exists():
        raise FileNotFoundError("AI æ‰§è¡Œå®Œæ¯•ï¼Œä½†æœªæ‰¾åˆ°ä»»ä½• .mid è¾“å‡ºæ–‡ä»¶ã€‚")

    if target_midi_path.exists():
        target_midi_path.unlink()

    if generated.resolve() != target_midi_path.resolve():
        generated.rename(target_midi_path)

    return target_midi_path


if __name__ == "__main__":
    import sys

    s = get_settings()
    print("\nğŸ§ª --- Step 03: AI è½¬æ¢å™¨èŠ‚ç‚¹æµ‹è¯• ---")
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python -m core.ai_converter <path/to/*_clean.wav>")
        raise SystemExit(1)

    p = Path(sys.argv[1])
    print("input =", p)
    print("H2S_AI_MODE =", os.getenv("H2S_AI_MODE"))
    print("use_stub_converter =", getattr(s, "use_stub_converter", None))
    out = audio_to_midi(p)
    print("midi =", out, "size =", out.stat().st_size)
